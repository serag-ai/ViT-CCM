{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Transformer Framework for Identifying Diabetic Peripheral Neuropathy in Corneal Confocal Microscopy Images &#x1F47E;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This code implements a Vision transfomer model to classifiy CCM images (not available publicly). \n",
    "\n",
    "<img src=\"\VT.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7013,
     "status": "ok",
     "timestamp": 1717954469871,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "RqKwSaKikz9V",
    "outputId": "8c4ac210-d730-406d-88a6-56457ffa8b05"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1717954469872,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "8pb6GI-Kkz9V"
   },
   "outputs": [],
   "source": [
    "### Get data\n",
    "base_path = '/data/'   #Here, include your own path\n",
    "\n",
    "input_shape = (384, 384, 3)  \n",
    "num_classes = 2\n",
    "batch_size = 20\n",
    "\n",
    "\n",
    "def load_data_from_folder(folder_path, input_size):\n",
    "    \"\"\"\n",
    "    Read images and labels for the dataset\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    files_list = sorted([filename for filename in os.listdir(folder_path) if not filename.startswith(\".\")])\n",
    "    \n",
    "            # iterate through each image in folder\n",
    "    for file in tqdm(files_list):\n",
    "\n",
    "                # get pathname of each image\n",
    "            img_path = os.path.join(folder_path, file)\n",
    "            \n",
    "                # Open and add the img to the list\n",
    "            image = cv2.imread(img_path)\n",
    "            \n",
    "            if image is not None:\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                image = np.expand_dims(image, axis=-1)\n",
    "                labels.append(int(file[0]))\n",
    "                images.append(image)\n",
    "\n",
    "                \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "     \n",
    "    labels = tf.keras.utils.to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "    data = [X_train, X_val, X_test, y_train, y_val, y_test]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1717954469872,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "ImXHJpNwkz9W",
    "outputId": "ffd64cca-8365-4715-e46a-e2620e64dd30"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test  = load_data_from_folder(base_path, input_size=input_shape)\n",
    "print(f\"train shape: {np.shape(X_train)}- y_train shape: {np.shape(y_train)}\")\n",
    "print(f\"val shape: {np.shape(X_val)}- y_val shape: {np.shape(y_val)}\")\n",
    "print(f\"test shape: {np.shape(X_test)}- y_test shape: {np.shape(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1717954469872,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "5ej4JXGokz9W"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load(image, target):\n",
    "    image = tf.cast(image, tf.float32) #/ 255.0\n",
    "    return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1717954469872,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "SZ5WCvrgkz9W"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_loader = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_train,y_train))\n",
    "    .map(load, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(7)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "\n",
    "val_loader = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_val,y_val))\n",
    "    .map(load, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(7)\n",
    "    .batch(batch_size)\n",
    ")\n",
    "\n",
    "test_loader = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((X_test,y_test))\n",
    "    .map(load, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(7)\n",
    "    .batch(batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1717954469872,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "E4rp7-iGkz9W"
   },
   "outputs": [],
   "source": [
    "input_shape = (384, 384, 1)\n",
    "learning_rate = 1e-4 \n",
    "weight_decay = 0.0001\n",
    "num_epochs = 100\n",
    "image_size = 256\n",
    "patch_size = 20  \n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 128 \n",
    "num_heads = 6 \n",
    "\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  \n",
    "transformer_layers = 3 \n",
    "mlp_head_units = [256]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 971,
     "status": "ok",
     "timestamp": 1717954470839,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "JsK1A8T9kz9W"
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Normalization(),\n",
    "        tf.keras.layers.Resizing(image_size, image_size),\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(factor=0.02),\n",
    "        tf.keras.layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1717954470839,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "dMYheVTSkz9X"
   },
   "outputs": [],
   "source": [
    "# Defining the Multilayer percepton \n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation = tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1717954470839,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "I3CcvGTBkz9X"
   },
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images = images,\n",
    "            sizes = [1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        #print(patches.shape)\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1717954478678,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "BURMTr_Rkz9X"
   },
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patches):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patches) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1717954479353,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "zO_xYdEikz9X"
   },
   "outputs": [],
   "source": [
    "def vit_model():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    augmented = data_augmentation(inputs)  # Augment data\n",
    "   \n",
    "    patches = Patches(patch_size)(augmented)  # Create patches\n",
    "    \n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)  # Encode patches\n",
    "\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1\n",
    "        x1 = layers.BatchNormalization()(encoded_patches)\n",
    "\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2\n",
    "        x3 = layers.BatchNormalization()(x2)\n",
    "        # MLP\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "    \n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "\n",
    "    representation = layers.LayerNormalization()(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "\n",
    "    features = mlp(representation, hidden_units = mlp_head_units, dropout_rate=0.5)\n",
    "\n",
    "    logits = layers.Dense(num_classes, activation='softmax')(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1717954479354,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "FFMR7X-Ekz9X"
   },
   "outputs": [],
   "source": [
    "def experiment(model, train_generator, val_generator, test_generator, num_epochs, learning_rate, weight_decay):\n",
    "    optimizer = Adam(learning_rate=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "        metrics=[\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.AUC(name=\"AUC\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=val_generator,\n",
    "    )\n",
    "\n",
    "    _, accuracy, auc = model.evaluate(test_generator)\n",
    "    print(f\"Test accuracy: {accuracy*100:.2f}%\")\n",
    "    print(f\"Test AUC: {auc:.2f}\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display model summary and # of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3690,
     "status": "ok",
     "timestamp": 1717954483042,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "KClxIg8-kz9X",
    "outputId": "6a4ac081-06c7-4774-9b5b-a72397a1b2ae",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vit_classifier = vit_model()\n",
    "vit_classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 189955,
     "status": "ok",
     "timestamp": 1717954672992,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "c-rbhO5Xkz9X",
    "outputId": "f3d6ace6-f7d1-411e-fa69-048d6f0e89c4"
   },
   "outputs": [],
   "source": [
    "history = experiment(vit_classifier, train_loader, val_loader, test_loader, num_epochs, learning_rate, weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation \n",
    "\n",
    "### Plot Metrics :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1439,
     "status": "ok",
     "timestamp": 1717954674428,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "Kv6qxINrkz9Y",
    "outputId": "02e15186-8224-4399-bc02-f76fcb82ac65"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# Plot history for accuracy\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# Plt history for loss\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot AUC figure\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.plot(history.history['AUC'])\n",
    "plt.plot(history.history['val_AUC'])\n",
    "plt.title('model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix and more metrics :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2854,
     "status": "ok",
     "timestamp": 1717954677280,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "90zklBMhkz9Y",
    "outputId": "a5d894fb-175b-4e12-b954-ff52db9b6fe5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = []\n",
    "truth = []\n",
    "for batch in test_loader.as_numpy_iterator():\n",
    "    images = batch[0]  # Access images\n",
    "    labels = batch[1]  # Access labels\n",
    "    # predicted labels (y_pred) and true labels (labels)\n",
    "    X_test = images\n",
    "    y_pred = vit_classifier.predict(X_test, verbose=0)\n",
    "    c1 = [list(array) for array in y_pred]\n",
    "    c2 = [list(array) for array in labels]\n",
    "    predictions.append(c1)\n",
    "    truth.append(c2)\n",
    "\n",
    "truth = np.vstack(truth)\n",
    "predictions = np.vstack(predictions)\n",
    "\n",
    "\n",
    "# Create confusion matrix\n",
    "cmtx = confusion_matrix(np.argmax(truth, axis=1), np.argmax(predictions,axis=1))\n",
    "print(cmtx)\n",
    "# Calculate specificity and sensitivity\n",
    "specificity = cmtx[0, 0] / (cmtx[0, 0] + cmtx[0, 1])\n",
    "sensitivity = cmtx[1, 1] / (cmtx[1, 1] + cmtx[1, 0])\n",
    "\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Sensitivity:\", sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradCam implementation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1717954677280,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "ka1-EE27kz9Y"
   },
   "outputs": [],
   "source": [
    "def get_img_array(img):\n",
    "    array = keras.preprocessing.image.img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 15255,
     "status": "error",
     "timestamp": 1717955233049,
     "user": {
      "displayName": "Tareq Mahmud",
      "userId": "12657323107601426229"
     },
     "user_tz": -360
    },
    "id": "I-0YJDWhkz9Y",
    "outputId": "f8191408-6f9b-4da8-c34b-43f51046fcc2"
   },
   "outputs": [],
   "source": [
    "def gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.input], [model.get_layer(last_conv_layer_name).output,  model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])  \n",
    "        class_channel = preds[:, pred_index]\n",
    "        \n",
    "        \n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))\n",
    "\n",
    "    last_conv_layer_output = last_conv_layer_output#[0]\n",
    "\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gradcam(img, heatmap, preds=[0,0], label=None, plot=None):\n",
    "\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    jet = matplotlib.colormaps.get_cmap(\"jet\")\n",
    "\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    alpha=0.4\n",
    "    superimposed_img = jet_heatmap * alpha + img   #Superimpose the heatmap on the original image\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "\n",
    "    # Display Grad CAM\n",
    "    plot.imshow(superimposed_img)\n",
    "    plot.set_title(\n",
    "    f\"Patient has {label} Predicted NO DPN: {preds[0]:.3f}\\n DPN: {preds[1]:.3f}\"\n",
    "    )\n",
    "    plot.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_name = 'layer_normalization'   #Last convolutional layer in the VIT model\n",
    "for batch in test_loader.as_numpy_iterator():\n",
    "    fig, axis = plt.subplots(10, 2, figsize=(50, 50))\n",
    "    vit_classifier.layers[-1].activation = None\n",
    "    images = batch[0]  # Access images\n",
    "    labels = batch[1]  # Access labels\n",
    "    for i in range(len(images)):\n",
    "        if labels[i][0] == 1:\n",
    "            rst = 'NO DPN'\n",
    "        else: \n",
    "            rst = 'DPN'\n",
    "    \n",
    "        vit_classifier.layers[-1].activation = None\n",
    "     \n",
    "        img_array = get_img_array(images[i])\n",
    "        preds = vit_classifier.predict(img_array, verbose=0)\n",
    "        heatmap = gradcam_heatmap(img_array, vit_classifier, last_conv_layer_name)\n",
    "\n",
    "        heatmap = np.reshape(heatmap, (12,12))\n",
    "        image_ = images[i]\n",
    "        ax = axis.flat\n",
    "        display_gradcam(image_, heatmap, preds=preds[0],label=rst,plot=ax[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The end! &#x1F3C3;"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "python3.11-g",
   "language": "python",
   "name": "python3.11g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
